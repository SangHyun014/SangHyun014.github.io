---
layout: post
title: "[Paper Review] An Image Is Worth 16x16 Words: Transformers for Image Recognition at Scale"
category: Paper
tags: [Paper, Computer Vision, ViT]
---

# An Image Is Worth 16X16 Words:Transformers for Image Recognition at Scale

## 1. Abstract

- Computer Vision에서는 Attention은 CNN이  함께 적용되어 사용되었습니다.
- 이 논문은 CNN 없이 sequence of image에 적용되어 Image Classification task를 잘 수행함을 보여줍니다.
- ViT(Vision Transfomer)는 CNN에 비해 뛰어난 성능을 보임과 동시에 필요한 연산량이 상당히 적습니다.

## 2. Introduction

- Transformer model 로 인해 NLP(Natural Language Processing) 분야에서 100B 이상의 매개변수를 가지는 매우 큰 모델 학습이 가능해졌습니다.
- 여전히 Large-Scale 이미지에 대해선 ResNet이 최신 기술이었습니다.
- NLP 에서 Transformer Scaling 성공하여 이미지에 적용하였습니다. 이미지를 patch로 분할하고, 이를 sequence of linear embedding로 input으로 사용합니다.
- ViT는 상당히 큰 규모로 pre-trained 되고, 적은 data 에서 전이학습 시 상당히 좋은 결과를 가져옵니다.
- 가장 좋은 모델은 ImageNet-88.55%, ImageNet_Real-90.72%, CIFAR_100-94.55% 등에서 상당한 정확도를 보여줍니다..

## 3. Method

### Vision Transformer(ViT)

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/28548b4a-3772-4592-ba14-5e261913dabb)

ViT의 모델의 구조

- 우선 input Image를 patch로 분리합니다. 이를 순서대로 embedding 하여 Transformer Encoding에 들어가게 됩니다. 이 때, 아래의 그림과 같은 Position Embedding 을 추가하여 위치 값을 보존해줍니다.

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/8cf92837-d93b-4ba9-99fe-73983c78fbc7)

- 다음 이미지는 각 이미지 별 Position Embedding 을 나타낸 것입니다.

Embedding 과정을 이미지를 통해 살펴보도록 하겠습니다.

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/77bac0ee-486d-45b5-bfce-20d85dae1265)

- 각 패치에 대한 Vector를 1차원 변환 후, Linear Projection 을 통해 하나의 벡터로 만들어 줍니다.
이를 3배 늘려서 각 값을 Value, Key, Query로 지정해 어텐션 스코어 연산 과정을 거치게 됩니다.

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/4f3357d0-8fb0-4659-a0cf-b9a59685f220)

- 각 Query 가 전체 Key 벡터에 대해 dot product를 진행하고, patch가 총 9개 이므로, 9개의 output이 나오게 됩니다.

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/81268b5e-1054-4bb4-a207-e1a67f0ca3b0)

- 위의 값을 Softmax 를 취해 확률 값으로 만들어 주어 Attention Score 를 완성합니다.
이 후, 이 값을 전체 Value 와 dot product 를 해주어 최종적으로 output 을 만들어냅니다.

- **Hybrid Architecture**(논문에서 제시)
    - 각 Patch를 linear projection이 아니라 CNN을 활용하여 나온 feature map을 input으로 활용합니다.

- **Fine-Tuning and Higher Resolusion**
    - pre-trained prediction head를 제거하고 zero-initialized D x K feedforward layer를 추가합니다. (K는 해결하고자 하는 task의 class 수 입니다.)
    - pre-trained 보다 high resolusion에서의 fine-tuning이 더 좋다고 합니다.

### Limitations

- 많은 data 로 pre-train 해야한다는 점 입니다.
- Fine-Tuning 시 Pre-Train 이미지보다 높은 해상도를 사용하면 성능 향상에 도움이 된다고 합니다.

### Conclusion

![image](https://github.com/SangHyun014/SangHyun014.github.io/assets/87685922/d70f5aee-87e2-481c-a303-b588274b1798)

Pre-Training 데이터가 적으면, 성능이 안 좋아진다고 합니다.

- 이는 Data가 많아야 함을 의미하게 됩니다.

- 기존 CNN보다 성능이 좋다는 것을 확인할 수 있습니다.
- Parameter에 한계가 없습니다. → 더 많은 data와 parameter 로 더 좋은 성능을 보이는 것을 알 수 있습니다.
